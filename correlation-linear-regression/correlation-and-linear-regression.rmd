---
title:    "Correlação e Regressão Linear"
subtitle: "Bioestatística em R"
author:   "André M Ribeiro-dos-Santos"
date:     "`r format(Sys.Date(), '%d de %m, %Y')`"
fontsize: 10pt
output:
  beamer_presentation:
    theme: "metropolis"
    latex_engine: xelatex
---

```{r setup, include = FALSE}
on_change_size <- function(before, options, envir) {
    if (before)
        return(paste(options$change_size))
}

knitr::knit_hooks$set(change_size = on_change_size)
knitr::opts_chunk$set(prompt = TRUE,
                      warning = FALSE,
                      dev.args=list(pointsize=18),
                      change_size='\\small')
```

## Objetivos

- Avaliar a associação entre medidas quantitativas.
- Reconhecer diferentes tipos de correlação.
- Ilustrar a relação entre medidas quantitativas.
- Reconhecer quando aplicar Pearson e Spearman.
- Conhecer principais transformações e quando aplicá-las.
- Modelar medidas através de uma regressão linear.
- Ilustrar a regressão e resíduos.
- Comparar diferente regressões.

# Correlação

## Imagine...

Em um estudo sobre diabetes, os pesquisadores observaram uma grande variação da
sensibilidade à insulina entre os pacientes. Como trabalhos anteriores
relacionaram essa variação com composição lipídica do tecido muscular. Foi
medido a sensibilidade à insulina e composição de ácidos graxos de 10 pacientes.

\begin{center}
  \usebeamerfont*{frametitle}
  A variação da sensibilidade à insulina está relacionada a
  composição de ácidos graxos?
\end{center}


```{r corExample, echo = FALSE}
n <- 10; hf <- ceiling(n/2)
x <- c(278, 496, 294, 434, 226, 319, 329, 162, 325, 351)
# y <- x/100 + 15 + rnorm(10, sd=.5)
y <- c(17.71, 20.06, 17.35, 19.49, 17.21, 18.76, 18.23, 16.28, 18.04, 18.35)

knitr::kable(data.frame(x[1:hf], y[1:hf], x[(hf+1):n], y[(hf+1):n]),
             col.names = rep(c("Insulin sensitivity",
                               "Fatty Acids (%)"), 2),
             digits = 2)
```

## Avaliando o problema

- As medidas em questão são categóricas ou quantitativas?
- Qual o tamanho da amostra?
- Qual a hipótese sendo avaliada?
- Qual a distribuição das medidas?

***

- As medidas em questão são categóricas ou quantitativas?
  **Ambas são quantitativas**
- Qual o tamanho da amostra?
  **10 pacientes**
- Qual a hipótese sendo avaliada?
  **As medidas são relacionadas.**

***

- Qual a distribuição das medidas? E como se relacionam?

```{r corDist, fig.height = 4}
y <- c(278, 496, 294, 434, 226, 319, 329, 162, 325, 351)
x <- c(17.71, 20.06, 17.35, 19.49, 17.21, 18.76,
       18.23, 16.28, 18.04, 18.35)

par(mfrow=c(1,3))
hist(x); hist(y)
plot(x, y)
```

## Correlação de Pearson

Quando desejamos avaliar se a variação de uma medida afeta outra medida
quantitativa, avaliamos a correlação linear das medidas com o coeficiente de
correlação de Pearson ($r$).

$$
    r = \dfrac{cov_{xy}}{s_x * s_y} =
        \dfrac{\sum (x-\bar{x})(y-\bar{y})}{\sum(x-\hat{x}) * \sum*y-\hat{y})}
$$

Uma propriedade interessante deste coeficiente é que $r^2$ corresponde ao
percentual da variabilidade em y explicada por x (ou vice-versa).

***

### Valores do coeficiente

O *coeficiente de correlação* ($r$) assume valores entre -1 e 1, indicando uma
correlação inversa em valores negativos, direta para valores positivos e zero
quando não há correlação.

```{r corCoefficient, echo = F, fig.height=6}
par(mfrow = c(2,2), oma=rep(1,4), mar=rep(2,4))
plot(1:10, 1:10, main = "r = 1", xlab="x", ylab="y")
abline(0, 1)
plot(1:10, 10-(1:10), main = "r = -1", xlab="x", ylab="y")
abline(10, -1)
plot(1:10, runif(10, 1, 10), main = "r = 0", xlab="x", ylab="y")
abline(6, 0)
plot(1:10,  2 * (1:10)^2 + (1:10)/2, main = "non-linear", xlab="x", ylab="y")
lines(1:10, 2 * (1:10)^2 + (1:10)/2)
```

***

```{r corDoc, eval = FALSE}
?cor
## Correlation, Variance and Covariance (Matrices)
## Description:
##      ‘var’, ‘cov’ and ‘cor’ compute the variance of ‘x’ and the
##      covariance or correlation of ‘x’ and ‘y’ if these are vectors.  If
##      ‘x’ and ‘y’ are matrices then the covariances (or correlations)
##      between the columns of ‘x’ and the columns of ‘y’ are computed.
## Usage:
##      var(x, y = NULL, na.rm = FALSE, use)
##      cov(x, y = NULL, use = "everything",
##          method = c("pearson", "kendall", "spearman"))
##      cor(x, y = NULL, use = "everything",
##          method = c("pearson", "kendall", "spearman"))
```

***

```{r corUseEx}
cov(x, y) / sqrt(var(x) * var(y))
cor(x, y)
cor(x, y)^2
```

## Teste de Correlação

Assumindo que $r$ apresenta uma distribuição normal, podemos testar a
significância da correlação observada.

$$ Ho: r = 0; ~~ Ha: R \neq 0 $$

$$ t = \dfrac{r}{EP_r} = r\sqrt \dfrac{n -2}{1 - r^2} $$

***

```{r corTestDoc, eval = FALSE}
?cor.test
## Test for Association/Correlation Between Paired Samples
## Description:
##      Test for association between paired samples, using one of
##      Pearson's product moment correlation coefficient, Kendall's
##      tau or Spearman's rho.
## Usage:
##      cor.test(x, y,
##               alternative = c("two.sided", "less", "greater"),
##               method = c("pearson", "kendall", "spearman"),
##               exact = NULL, conf.level = 0.95,
##               continuity = FALSE, ...)
##      ## S3 method for class 'formula'
##      cor.test(formula, data, subset, na.action, ...)
```

***

```{r corTestEx}
cor.test(x, y)
```

## Erros comuns

1. Correlação não implica em causa.
2. Focar no P-value, no lugar do coeficiente.
3. Assumir correlação sem  plotar relação.

```{r ascombeEx, echo = FALSE, fig.height = 5}
par(mfrow = c(2,2), oma=rep(1,4), mar=rep(2,4))
for (i in 1:4) {
    x = anscombe[, paste("x", i, sep="")];
    y = anscombe[, paste("y", i, sep="")];
    plot(y~x, main = sprintf("Cor(x, y) = %.3f", cor(x, y)),
         xlim=c(0,20), ylim=c(0, 15));
    abline(lm(y~x))
}
```

## Exercícios - Correlação de Pearson

## Parece que o jogo virou

## Correlação de Spearman

## Exercícios - Correlação de Spearman

# Regressão Linear

## Imagine...

## Formulas
